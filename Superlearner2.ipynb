{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Binary Classification using a SuperLearner\"\"\"\n",
    "\n",
    "from numpy import hstack\n",
    "from numpy import vstack\n",
    "from numpy import asarray\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# create a list of base-models -> plug your own here\n",
    "def get_models():\n",
    "    models = list() # Emply list for future storage\n",
    "    models.append(LogisticRegression(solver='liblinear'))\n",
    "    models.append(DecisionTreeClassifier())\n",
    "    models.append(SVC(gamma='scale', probability=True))\n",
    "    models.append(RandomForestClassifier(n_estimators=10))\n",
    "    models.append(ExtraTreesClassifier(n_estimators=10))\n",
    "    models.append(GaussianNB())\n",
    "    models.append(KNeighborsClassifier())\n",
    "    models.append(AdaBoostClassifier())\n",
    "    models.append(BaggingClassifier(n_estimators=10))\n",
    "    return models\n",
    "\n",
    "# Collect out of fold predictions form k-fold cross validation\n",
    "def get_out_of_fold_predictions(X, y, models):\n",
    "    meta_X, meta_y = list(), list()\n",
    "    # define split of data\n",
    "    kfold = KFold(n_splits=10, shuffle=True)\n",
    "    # enumerate splits\n",
    "    for train_ix, test_ix in kfold.split(X):\n",
    "        fold_yhats = list()\n",
    "        # get data\n",
    "        train_X, test_X = X[train_ix], X[test_ix]\n",
    "        train_y, test_y = y[train_ix], y[test_ix]\n",
    "        meta_y.extend(test_y)\n",
    "        \n",
    "        # fit and make predictions with each sub-model\n",
    "        for submodel in models:\n",
    "            submodel.fit(train_X, train_y)\n",
    "            yhat = submodel.predict_proba(test_X)\n",
    "            # store columns\n",
    "            fold_yhats.append(yhat)\n",
    "        # store fold yhats as columns\n",
    "        meta_X.append(hstack(fold_yhats))\n",
    "    return vstack(meta_X), asarray(meta_y)\n",
    "\n",
    "    # fit all base models on the training dataset\n",
    "    def fit_base_models(X, y, models):\n",
    "    for model in models:\n",
    "        model.fit(X, y)\n",
    "\n",
    "    # fit a meta model -> LogisticRegression\n",
    "    def fit_meta_model(X, y):\n",
    "    model = LogisticRegression(solver='liblinear')\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "    # evaluate a list of models on a dataset\n",
    "    def evaluate_models(X, y, models):\n",
    "    for model in models:\n",
    "        yhat = model.predict(X)\n",
    "        acc = accuracy_score(y, yhat)\n",
    "        print('%s: %.3f' % (model.__class__.__name__, acc*100))\n",
    "\n",
    "    # make predictions with stacked model\n",
    "    def super_learner_predictions(X, models, meta_model):\n",
    "    meta_X = list()\n",
    "    for model in models:\n",
    "        yhat = model.predict_proba(X)\n",
    "        meta_X.append(yhat)\n",
    "    meta_X = hstack(meta_X)\n",
    "    # predict\n",
    "    return meta_model.predict(meta_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (500, 100) (500,) Test (500, 100) (500,)\n",
      "Meta  (500, 18) (500,)\n",
      "LogisticRegression: 97.400\n",
      "DecisionTreeClassifier: 74.000\n",
      "SVC: 98.600\n",
      "GaussianNB: 98.800\n",
      "KNeighborsClassifier: 93.200\n",
      "AdaBoostClassifier: 90.800\n",
      "BaggingClassifier: 82.400\n",
      "RandomForestClassifier: 85.200\n",
      "ExtraTreesClassifier: 85.000\n",
      "Super Learner: 99.200\n"
     ]
    }
   ],
   "source": [
    "# create the inputs and outputs\n",
    "X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\n",
    "# split\n",
    "X, X_val, y, y_val = train_test_split(X, y, test_size=0.50)\n",
    "print('Train', X.shape, y.shape, 'Test', X_val.shape, y_val.shape)\n",
    "\n",
    "# Get models\n",
    "models = get_models()\n",
    "# get out of fold predictions\n",
    "meta_X, meta_y = get_out_of_fold_predictions(X, y, models)\n",
    "print('Meta Result: ', meta_X.shape, meta_y.shape)\n",
    "# fit base models\n",
    "fit_base_models(X, y, models)\n",
    "# fit the meta model\n",
    "meta_model = fit_meta_model(meta_X, meta_y)\n",
    "\n",
    "# evaluate base models\n",
    "evaluate_models(X_val, y_val, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate meta model\n",
    "yhat = super_learner_predictions(X_val, models, meta_model)\n",
    "print('Super Learner Performance: %.3f' % (accuracy_score(y_val, yhat) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
